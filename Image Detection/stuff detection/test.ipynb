{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/tirthpatel/Desktop/Computer Vision/Image Detection/stuff detection/data/images/train/00d9a357b10f81d8.jpg: 480x640 2 Lamps, 1 Bed, 100.4ms\n",
      "Speed: 4.4ms preprocess, 100.4ms inference, 10.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'Lamp', 1: 'Table', 2: 'Chair', 3: 'Couch', 4: 'Bed'}\n",
      "obb: None\n",
      "orig_img: array([[[  5,  78,  92],\n",
      "        [  3,  74,  88],\n",
      "        [  3,  72,  89],\n",
      "        ...,\n",
      "        [105, 194, 214],\n",
      "        [ 90, 176, 198],\n",
      "        [ 93, 179, 203]],\n",
      "\n",
      "       [[  3,  78,  92],\n",
      "        [  3,  76,  90],\n",
      "        [  2,  71,  88],\n",
      "        ...,\n",
      "        [ 91, 183, 200],\n",
      "        [100, 191, 212],\n",
      "        [ 90, 181, 202]],\n",
      "\n",
      "       [[  3,  80,  96],\n",
      "        [  7,  84, 100],\n",
      "        [  9,  81,  99],\n",
      "        ...,\n",
      "        [ 89, 185, 201],\n",
      "        [ 93, 191, 209],\n",
      "        [ 86, 184, 202]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0,  18],\n",
      "        [  0,   0,  18],\n",
      "        [  0,   0,  20],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,  15],\n",
      "        [  0,   1,  16],\n",
      "        [  0,   1,  21],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,  13],\n",
      "        [  0,   1,  16],\n",
      "        [  0,   2,  20],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]]], dtype=uint8)\n",
      "orig_shape: (760, 1024)\n",
      "path: '/Users/tirthpatel/Desktop/Computer Vision/Image Detection/stuff detection/data/images/train/00d9a357b10f81d8.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/tirthpatel/Desktop/NLP/PDF-chat/runs/detect/predict'\n",
      "speed: {'preprocess': 4.389047622680664, 'inference': 100.36301612854004, 'postprocess': 10.230064392089844}]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('/Users/tirthpatel/Desktop/Computer Vision/Image Detection/stuff detection/yolo logs/train2/weights/best.pt')\n",
    "\n",
    "# Run inference\n",
    "results = model('/Users/tirthpatel/Desktop/Computer Vision/Image Detection/stuff detection/data/images/train/00d9a357b10f81d8.jpg')\n",
    "\n",
    "# Results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([4., 0., 0.])\n",
       "conf: tensor([0.9383, 0.5379, 0.3448])\n",
       "data: tensor([[0.0000e+00, 2.9997e+02, 8.8211e+02, 7.5459e+02, 9.3834e-01, 4.0000e+00],\n",
       "        [3.8421e+02, 4.4297e+02, 4.1548e+02, 5.1199e+02, 5.3794e-01, 0.0000e+00],\n",
       "        [9.5372e+02, 3.6647e+02, 1.0240e+03, 5.9851e+02, 3.4477e-01, 0.0000e+00]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (760, 1024)\n",
       "shape: torch.Size([3, 6])\n",
       "xywh: tensor([[441.0554, 527.2773, 882.1107, 454.6238],\n",
       "        [399.8461, 477.4833,  31.2726,  69.0174],\n",
       "        [988.8581, 482.4907,  70.2838, 232.0466]])\n",
       "xywhn: tensor([[0.4307, 0.6938, 0.8614, 0.5982],\n",
       "        [0.3905, 0.6283, 0.0305, 0.0908],\n",
       "        [0.9657, 0.6349, 0.0686, 0.3053]])\n",
       "xyxy: tensor([[   0.0000,  299.9654,  882.1107,  754.5892],\n",
       "        [ 384.2098,  442.9746,  415.4823,  511.9920],\n",
       "        [ 953.7162,  366.4674, 1024.0000,  598.5140]])\n",
       "xyxyn: tensor([[0.0000, 0.3947, 0.8614, 0.9929],\n",
       "        [0.3752, 0.5829, 0.4057, 0.6737],\n",
       "        [0.9314, 0.4822, 1.0000, 0.7875]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 299.9654235839844,\n",
       " 882.1107177734375,\n",
       " 754.5892333984375,\n",
       " 0.9383384585380554,\n",
       " 4.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.data[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = results[0].orig_img\n",
    "for box in results[0].boxes:\n",
    "    x1, y1, x2, y2 = box[:4]\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Get the original image from the Results object\n",
    "image = results[0].orig_img\n",
    "\n",
    "# Show the image using OpenCV\n",
    "cv2.imshow(\"Predicted Image\", image)\n",
    "# Draw bounding boxes on the image\n",
    "for box in boxes.data:\n",
    "    x1, y1, x2, y2, conf, cls = box.tolist()\n",
    "    cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "    # Draw class label on the image\n",
    "    class_label = model.names[int(cls)]\n",
    "    cv2.putText(image, class_label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "# Show the image using OpenCV\n",
    "cv2.imshow(\"Predicted Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
